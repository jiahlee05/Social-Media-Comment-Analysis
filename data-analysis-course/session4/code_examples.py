# Session 4: í…ìŠ¤íŠ¸ ë¶„ì„ & ì›Œë“œí´ë¼ìš°ë“œ
# Code Examples

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import re

# NLTK ë¼ì´ë¸ŒëŸ¬ë¦¬
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.sentiment import SentimentIntensityAnalyzer

# ìµœì´ˆ 1íšŒ ë‹¤ìš´ë¡œë“œ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰)
# nltk.download('punkt')
# nltk.download('stopwords')
# nltk.download('wordnet')
# nltk.download('vader_lexicon')

print("=" * 60)
print("Session 4: í…ìŠ¤íŠ¸ ë¶„ì„ & ì›Œë“œí´ë¼ìš°ë“œ")
print("=" * 60)

# ============================================
# Part 1: í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
# ============================================

print("\n" + "=" * 60)
print("Part 1: í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬")
print("=" * 60)

# ìƒ˜í”Œ í…ìŠ¤íŠ¸
sample_text = """
I absolutely LOVE this product! It's amazing and works perfectly.
The customer service was excellent. Highly recommended!!! ğŸ˜ŠğŸ˜ŠğŸ˜Š
#BestPurchase #HappyCustomer
"""

print(f"\nì›ë³¸ í…ìŠ¤íŠ¸:\n{sample_text}")

# ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_text(text, remove_numbers=True):
    # ì†Œë¬¸ì ë³€í™˜
    text = text.lower()

    # URL ì œê±°
    text = re.sub(r'http\S+|www\S+', '', text)

    # ì´ë©”ì¼ ì œê±°
    text = re.sub(r'\S+@\S+', '', text)

    # í•´ì‹œíƒœê·¸ ê¸°í˜¸ ì œê±° (ë‹¨ì–´ëŠ” ìœ ì§€)
    text = re.sub(r'#', '', text)

    # ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)

    # ìˆ«ì ì œê±° (ì˜µì…˜)
    if remove_numbers:
        text = re.sub(r'\d+', '', text)

    # í† í°í™”
    tokens = word_tokenize(text)

    # ë¶ˆìš©ì–´ ì œê±°
    stop_words = set(stopwords.words('english'))
    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]

    # í‘œì œì–´ ì¶”ì¶œ
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(t) for t in tokens]

    return tokens

# ì „ì²˜ë¦¬ ì‹¤í–‰
cleaned_tokens = preprocess_text(sample_text)
print(f"\nì „ì²˜ë¦¬ ê²°ê³¼: {cleaned_tokens}")

# ============================================
# Part 2: ë°ì´í„° ë¡œë“œ ë° ëŒ€ëŸ‰ ì „ì²˜ë¦¬
# ============================================

print("\n" + "=" * 60)
print("Part 2: ì†Œì…œ ë¯¸ë””ì–´ ëŒ“ê¸€ ë°ì´í„° ë¶„ì„")
print("=" * 60)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('../datasets/social_media_comments.csv')
print(f"\në°ì´í„° ë¡œë“œ: {df.shape}")
print(df.head())

# ëª¨ë“  ëŒ“ê¸€ ì „ì²˜ë¦¬
df['cleaned_tokens'] = df['comment'].apply(preprocess_text)
df['cleaned_text'] = df['cleaned_tokens'].apply(lambda x: ' '.join(x))

print("\nì „ì²˜ë¦¬ ì˜ˆì‹œ:")
for i in range(3):
    print(f"\nì›ë³¸: {df.iloc[i]['comment']}")
    print(f"ì „ì²˜ë¦¬: {df.iloc[i]['cleaned_text']}")

# ============================================
# Part 3: ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
# ============================================

print("\n" + "=" * 60)
print("Part 3: ì›Œë“œí´ë¼ìš°ë“œ")
print("=" * 60)

# ì „ì²´ ëŒ“ê¸€ í•©ì¹˜ê¸°
all_text = ' '.join(df['cleaned_text'])

# ê¸°ë³¸ ì›Œë“œí´ë¼ìš°ë“œ
wordcloud = WordCloud(width=1200, height=600,
                      background_color='white',
                      colormap='viridis',
                      max_words=100).generate(all_text)

plt.figure(figsize=(15, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud: Most Common Words in Comments',
          fontsize=18, fontweight='bold')
plt.tight_layout()
plt.savefig('session4_wordcloud_all.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì™„ë£Œ")

# ë¹ˆë„ìˆ˜ ë¶„ì„
all_words = []
for tokens in df['cleaned_tokens']:
    all_words.extend(tokens)

word_freq = Counter(all_words)
print("\nê°€ì¥ ë¹ˆë²ˆí•œ ë‹¨ì–´ Top 20:")
for word, count in word_freq.most_common(20):
    print(f"  {word}: {count}")

# ============================================
# Part 4: ê°ì„± ë¶„ì„
# ============================================

print("\n" + "=" * 60)
print("Part 4: ê°ì„± ë¶„ì„")
print("=" * 60)

# VADER ê°ì„± ë¶„ì„ê¸°
sia = SentimentIntensityAnalyzer()

# ê°ì„± ì ìˆ˜ ê³„ì‚°
df['sentiment_scores'] = df['comment'].apply(lambda x: sia.polarity_scores(x))
df['sentiment_compound'] = df['sentiment_scores'].apply(lambda x: x['compound'])
df['sentiment_pos'] = df['sentiment_scores'].apply(lambda x: x['pos'])
df['sentiment_neg'] = df['sentiment_scores'].apply(lambda x: x['neg'])
df['sentiment_neu'] = df['sentiment_scores'].apply(lambda x: x['neu'])

# ë²”ì£¼í™”
def categorize_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

df['sentiment'] = df['sentiment_compound'].apply(categorize_sentiment)

# ê°ì„± ë¶„í¬
print("\nê°ì„± ë¶„í¬:")
print(df['sentiment'].value_counts())
print(f"\nê¸ì • ë¹„ìœ¨: {(df['sentiment'] == 'Positive').sum() / len(df) * 100:.1f}%")
print(f"ë¶€ì • ë¹„ìœ¨: {(df['sentiment'] == 'Negative').sum() / len(df) * 100:.1f}%")
print(f"ì¤‘ë¦½ ë¹„ìœ¨: {(df['sentiment'] == 'Neutral').sum() / len(df) * 100:.1f}%")

# ê°ì„± ë¶„í¬ ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# ì¹´ìš´íŠ¸ í”Œë¡¯
sns.countplot(x='sentiment', data=df, ax=axes[0],
              palette={'Positive': '#4CAF50', 'Neutral': '#FFC107', 'Negative': '#F44336'})
axes[0].set_title('Sentiment Distribution (Count)', fontsize=14, fontweight='bold')
axes[0].set_ylabel('Count')

# ì ìˆ˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
axes[1].hist(df['sentiment_compound'], bins=50, color='skyblue', edgecolor='black')
axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Neutral')
axes[1].axvline(0.05, color='green', linestyle='--', linewidth=2, alpha=0.5)
axes[1].axvline(-0.05, color='red', linestyle='--', linewidth=2, alpha=0.5)
axes[1].set_xlabel('Sentiment Score')
axes[1].set_ylabel('Frequency')
axes[1].set_title('Distribution of Sentiment Scores', fontsize=14, fontweight='bold')
axes[1].legend()

plt.tight_layout()
plt.savefig('session4_sentiment_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# ============================================
# Part 5: í”Œë«í¼ë³„ ê°ì„± ë¹„êµ
# ============================================

print("\n" + "=" * 60)
print("Part 5: í”Œë«í¼ë³„ ê°ì„± ë¹„êµ")
print("=" * 60)

if 'platform' in df.columns:
    # í”Œë«í¼ë³„ ê°ì„± í†µê³„
    platform_sentiment = df.groupby('platform')['sentiment_compound'].agg(['mean', 'median', 'std'])
    print("\ní”Œë«í¼ë³„ ê°ì„± ì ìˆ˜:")
    print(platform_sentiment.round(3))

    # í¬ë¡œìŠ¤íƒ­
    sentiment_crosstab = pd.crosstab(df['platform'], df['sentiment'], normalize='index') * 100
    print("\ní”Œë«í¼ë³„ ê°ì„± ë¹„ìœ¨ (%):")
    print(sentiment_crosstab.round(1))

    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # ìŠ¤íƒ ë°” ì°¨íŠ¸
    sentiment_crosstab.plot(kind='bar', stacked=True, ax=axes[0],
                           color=['#F44336', '#FFC107', '#4CAF50'])
    axes[0].set_title('Sentiment Distribution by Platform (%)',
                     fontsize=14, fontweight='bold')
    axes[0].set_ylabel('Percentage')
    axes[0].set_xlabel('Platform')
    axes[0].legend(title='Sentiment')
    axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')

    # ë°•ìŠ¤í”Œë¡¯
    sns.boxplot(x='platform', y='sentiment_compound', data=df, ax=axes[1])
    axes[1].axhline(0, color='red', linestyle='--', linewidth=1)
    axes[1].set_title('Sentiment Score by Platform', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('Sentiment Score')
    axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')

    plt.tight_layout()
    plt.savefig('session4_platform_sentiment.png', dpi=300, bbox_inches='tight')
    plt.show()

# ============================================
# Part 6: ê¸ì •/ë¶€ì • ì›Œë“œí´ë¼ìš°ë“œ
# ============================================

print("\n" + "=" * 60)
print("Part 6: ê¸ì •/ë¶€ì • ì›Œë“œí´ë¼ìš°ë“œ")
print("=" * 60)

# ê¸ì •/ë¶€ì • ëŒ“ê¸€ ë¶„ë¦¬
positive_comments = df[df['sentiment'] == 'Positive']['cleaned_text']
negative_comments = df[df['sentiment'] == 'Negative']['cleaned_text']

print(f"\nê¸ì • ëŒ“ê¸€: {len(positive_comments)}ê°œ")
print(f"ë¶€ì • ëŒ“ê¸€: {len(negative_comments)}ê°œ")

# ê¸ì • ì›Œë“œí´ë¼ìš°ë“œ
if len(positive_comments) > 0:
    pos_text = ' '.join(positive_comments)
    wc_positive = WordCloud(width=800, height=600,
                           background_color='white',
                           colormap='Greens',
                           max_words=80).generate(pos_text)

# ë¶€ì • ì›Œë“œí´ë¼ìš°ë“œ
if len(negative_comments) > 0:
    neg_text = ' '.join(negative_comments)
    wc_negative = WordCloud(width=800, height=600,
                           background_color='white',
                           colormap='Reds',
                           max_words=80).generate(neg_text)

# ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(16, 8))

axes[0].imshow(wc_positive, interpolation='bilinear')
axes[0].set_title('Positive Comments Keywords',
                 fontsize=16, fontweight='bold', color='green')
axes[0].axis('off')

axes[1].imshow(wc_negative, interpolation='bilinear')
axes[1].set_title('Negative Comments Keywords',
                 fontsize=16, fontweight='bold', color='red')
axes[1].axis('off')

plt.tight_layout()
plt.savefig('session4_sentiment_wordclouds.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… ê°ì„±ë³„ ì›Œë“œí´ë¼ìš°ë“œ ì™„ì„±")

# ============================================
# Part 7: ì¢…í•© ëŒ€ì‹œë³´ë“œ
# ============================================

print("\n" + "=" * 60)
print("Part 7: ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
print("=" * 60)

fig = plt.figure(figsize=(18, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# 1. ì „ì²´ ì›Œë“œí´ë¼ìš°ë“œ
ax1 = fig.add_subplot(gs[0, :2])
ax1.imshow(wordcloud, interpolation='bilinear')
ax1.set_title('1. Most Common Words', fontsize=13, fontweight='bold')
ax1.axis('off')

# 2. ê°ì„± ë¶„í¬
ax2 = fig.add_subplot(gs[0, 2])
sentiment_counts = df['sentiment'].value_counts()
colors = [{'Positive': '#4CAF50', 'Neutral': '#FFC107', 'Negative': '#F44336'}[s]
          for s in sentiment_counts.index]
ax2.pie(sentiment_counts.values, labels=sentiment_counts.index,
       autopct='%1.1f%%', colors=colors, startangle=90)
ax2.set_title('2. Sentiment Distribution', fontsize=13, fontweight='bold')

# 3. í”Œë«í¼ë³„ ëŒ“ê¸€ ìˆ˜
if 'platform' in df.columns:
    ax3 = fig.add_subplot(gs[1, :])
    platform_counts = df['platform'].value_counts()
    ax3.barh(platform_counts.index, platform_counts.values,
            color='skyblue', edgecolor='black')
    ax3.set_xlabel('Number of Comments')
    ax3.set_title('3. Comments by Platform', fontsize=13, fontweight='bold')
    ax3.grid(axis='x', alpha=0.3)

# 4. ê°ì„± ì ìˆ˜ ë¶„í¬
ax4 = fig.add_subplot(gs[2, 0])
ax4.hist(df['sentiment_compound'], bins=30, color='coral', alpha=0.7, edgecolor='black')
ax4.axvline(0, color='red', linestyle='--', linewidth=2)
ax4.set_xlabel('Sentiment Score')
ax4.set_ylabel('Frequency')
ax4.set_title('4. Score Distribution', fontsize=13, fontweight='bold')
ax4.grid(axis='y', alpha=0.3)

# 5. Top í‚¤ì›Œë“œ
ax5 = fig.add_subplot(gs[2, 1])
top_words = word_freq.most_common(10)
words, counts = zip(*top_words)
ax5.barh(words, counts, color='lightgreen', edgecolor='black')
ax5.set_xlabel('Frequency')
ax5.set_title('5. Top 10 Keywords', fontsize=13, fontweight='bold')
ax5.grid(axis='x', alpha=0.3)

# 6. ì¸ì‚¬ì´íŠ¸
ax6 = fig.add_subplot(gs[2, 2])
ax6.axis('off')
insights = f"""
ğŸ“Š ë¶„ì„ ìš”ì•½

ì´ ëŒ“ê¸€: {len(df)}ê°œ

ê°ì„± ë¶„í¬:
â€¢ ê¸ì •: {(df['sentiment']=='Positive').sum()}
â€¢ ì¤‘ë¦½: {(df['sentiment']=='Neutral').sum()}
â€¢ ë¶€ì •: {(df['sentiment']=='Negative').sum()}

í‰ê·  ê°ì„± ì ìˆ˜:
{df['sentiment_compound'].mean():.3f}

ê°€ì¥ ë¹ˆë²ˆí•œ ë‹¨ì–´:
"{word_freq.most_common(1)[0][0]}"
"""
ax6.text(0.1, 0.9, insights, fontsize=10, verticalalignment='top',
        family='monospace', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))

plt.suptitle('Social Media Comments Analysis Dashboard',
             fontsize=18, fontweight='bold', y=0.995)
plt.savefig('session4_dashboard.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… ì¢…í•© ëŒ€ì‹œë³´ë“œ ì™„ì„±!")

# ============================================
# ë§ˆë¬´ë¦¬
# ============================================

print("\n" + "=" * 60)
print("ğŸ‰ Session 4 ì™„ë£Œ!")
print("=" * 60)
print("""
ì˜¤ëŠ˜ ë°°ìš´ ê²ƒ:
âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í† í°í™”, ë¶ˆìš©ì–´ ì œê±°, í‘œì œì–´ ì¶”ì¶œ)
âœ… ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•
âœ… VADER ê°ì„± ë¶„ì„
âœ… í”Œë«í¼ë³„ ê°ì„± ë¹„êµ
âœ… ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ë¶„ì„

ë‹¤ìŒ ì‹œê°„:
ğŸ“‹ ì‹¤í—˜ ë°ì´í„° ì²˜ë¦¬
ğŸ“Š ì¢…í•© ë¶„ì„ íŒŒì´í”„ë¼ì¸
ğŸ“ ìë™í™”ëœ ë³´ê³ ì„œ ìƒì„±
ğŸ¯ ìµœì¢… í”„ë¡œì íŠ¸
""")
