"""
í†µí•© ì›Œí¬í”Œë¡œìš°: statlingua + vitals ê²°í•©
ì‹¤ì œ ì—…ë¬´ ì‹œë‚˜ë¦¬ì˜¤
"""

from anthropic import Anthropic
import pandas as pd
import numpy as np
import statsmodels.api as sm
from pathlib import Path
import sys
import os

# ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from statlingua_py.explainer import StatLinguaExplainer
from vitals_py.task import Task
from vitals_py.scorers import model_graded_qa


def workflow_1_weekly_mentoring_automation():
    """
    ì›Œí¬í”Œë¡œìš° 1: ì£¼ê°„ ë©˜í† ë§ ìë£Œ ìë™ ìƒì„± ë° í’ˆì§ˆ ê´€ë¦¬
    """
    print("="*70)
    print("ì›Œí¬í”Œë¡œìš° 1: ì£¼ê°„ ë©˜í† ë§ ìë£Œ ìƒì„± ë° í’ˆì§ˆ í‰ê°€")
    print("="*70)

    client = Anthropic()

    # 12ì£¼ ì»¤ë¦¬í˜ëŸ¼
    curriculum = pd.DataFrame({
        'week': range(1, 13),
        'topic': [
            "Python ê¸°ì´ˆ ë¬¸ë²•",
            "ìë£Œêµ¬ì¡° (ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬)",
            "ì œì–´ë¬¸ (if, for, while)",
            "í•¨ìˆ˜ì™€ ëª¨ë“ˆ",
            "íŒŒì¼ ì…ì¶œë ¥",
            "ì˜ˆì™¸ ì²˜ë¦¬",
            "ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°",
            "Pandas ê¸°ì´ˆ",
            "ë°ì´í„° ì‹œê°í™”",
            "ì›¹ ìŠ¤í¬ë˜í•‘",
            "API í™œìš©",
            "í”„ë¡œì íŠ¸ í†µí•©"
        ],
        'level': [
            'beginner', 'beginner', 'beginner', 'intermediate',
            'intermediate', 'intermediate', 'intermediate', 'intermediate',
            'advanced', 'advanced', 'advanced', 'advanced'
        ]
    })

    # íŠ¹ì • ì£¼ì°¨ ìë£Œ ìƒì„± (ì˜ˆ: 5ì£¼ì°¨)
    week = 5
    topic = curriculum.loc[curriculum['week'] == week, 'topic'].values[0]
    level = curriculum.loc[curriculum['week'] == week, 'level'].values[0]

    print(f"\nğŸ“š {week}ì£¼ì°¨: {topic} (ë‚œì´ë„: {level})")

    # 1. ìë£Œ ìƒì„±
    prompt = f"""
ì£¼ì œ: {topic}
ëŒ€ìƒ: ëŒ€í•™ìƒ ì´ˆë³´ì
ë‚œì´ë„: {level}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•™ìŠµ ìë£Œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

1. í•µì‹¬ ê°œë… (3-5ë¬¸ì¥)
2. ì‹¤ìƒí™œ ë¹„ìœ 
3. ì½”ë“œ ì˜ˆì œ (ì£¼ì„ í¬í•¨)
4. ì—°ìŠµ ë¬¸ì œ 3ê°œ (íŒíŠ¸ í¬í•¨)
"""

    response = client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=3000,
        messages=[{"role": "user", "content": prompt}]
    )

    material = response.content[0].text

    # ìë£Œ ì €ì¥
    output_dir = Path(os.path.dirname(__file__)) / "mentoring_materials"
    output_dir.mkdir(exist_ok=True)

    with open(output_dir / f"week{week}_{topic.replace(' ', '_')}.md", 'w', encoding='utf-8') as f:
        f.write(f"# {week}ì£¼ì°¨: {topic}\n\n")
        f.write(material)

    print(f"âœ“ ìë£Œ ìƒì„± ì™„ë£Œ: {output_dir / f'week{week}_{topic.replace(\" \", \"_\")}.md'}")

    # 2. í’ˆì§ˆ í‰ê°€ (vitals ì‚¬ìš©)
    quality_dataset = pd.DataFrame({
        'input': [f"{topic}ì„ ì´ˆë³´ìì—ê²Œ ì„¤ëª…í•˜ì„¸ìš”"],
        'target': ["ëª…í™•í•œ ê°œë…, ë¹„ìœ , ì˜ˆì œ, ì—°ìŠµë¬¸ì œ í¬í•¨"]
    })

    def material_solver(inputs, **kwargs):
        # ì´ë¯¸ ìƒì„±ëœ ìë£Œ ì‚¬ìš©
        return {
            'result': [material],
            'solver_metadata': [{'generated': True}]
        }

    quality_task = Task(
        dataset=quality_dataset,
        solver=material_solver,
        scorer=model_graded_qa(
            client=client,
            instructions="""
êµìœ¡ ìë£Œì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
1. ê°œë…ì´ ëª…í™•í•œê°€?
2. ë¹„ìœ ê°€ ì ì ˆí•œê°€?
3. ì˜ˆì œê°€ ì‹¤í–‰ ê°€ëŠ¥í•œê°€?
4. ì—°ìŠµë¬¸ì œê°€ ì ì ˆí•œê°€?
"""
        ),
        name=f"week{week}_quality"
    )

    quality_task.eval()

    print(f"\ní’ˆì§ˆ í‰ê°€ ì ìˆ˜: {quality_task.metrics.accuracy:.0%}")

    return material


def workflow_2_research_report_automation():
    """
    ì›Œí¬í”Œë¡œìš° 2: ì—°êµ¬ ë³´ê³ ì„œ ìë™ ìƒì„± (OLED)
    """
    print("\n" + "="*70)
    print("ì›Œí¬í”Œë¡œìš° 2: OLED ì—°êµ¬ ë³´ê³ ì„œ ìë™í™”")
    print("="*70)

    # OLED ì‹¤í—˜ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
    np.random.seed(2026)
    n = 60

    experiments = {
        'tandem_efficiency': pd.DataFrame({
            'efficiency': 25 + 5*np.random.randn(n),
            'layer1_nm': 50 + 10*np.random.randn(n),
            'layer2_nm': 40 + 8*np.random.randn(n),
            'dopant_pct': 2 + 0.3*np.random.randn(n)
        }),
        'reliability': pd.DataFrame({
            'lifetime_hours': 10000 + 2000*np.random.randn(n),
            'temperature_C': 80 + 10*np.random.randn(n),
            'humidity_pct': 50 + 10*np.random.randn(n)
        }),
        'birefringence': pd.DataFrame({
            'crack_prob': np.random.beta(2, 5, n),
            'laser_power_W': 100 + 20*np.random.randn(n),
            'glass_thickness_um': 500 + 50*np.random.randn(n)
        })
    }

    client = Anthropic()
    explainer = StatLinguaExplainer(client=client)

    report_sections = []

    for exp_name, data in experiments.items():
        print(f"\në¶„ì„ ì¤‘: {exp_name}")

        # í†µê³„ ë¶„ì„
        y_col = data.columns[0]
        X_cols = data.columns[1:]

        X = sm.add_constant(data[X_cols])
        model = sm.OLS(data[y_col], X)
        results = model.fit()

        # ê²½ì˜ì§„ìš© ìš”ì•½
        exec_summary = explainer.explain(
            results,
            context=f"""
ì‹¤í—˜: {exp_name}
ëª©í‘œ: 2026ë…„ ì–‘ì‚° ì¤€ë¹„
ì¤‘ìš”ì„±: ì°¨ì„¸ëŒ€ OLED íŒ¨ë„ ê²½ìŸë ¥ í™•ë³´
""",
            audience="manager",
            verbosity="brief"
        )

        # ì—°êµ¬ì§„ìš© ìƒì„¸
        tech_detail = explainer.explain(
            results,
            context=f"ì‹¤í—˜: {exp_name}",
            audience="researcher",
            verbosity="detailed"
        )

        report_sections.append({
            'experiment': exp_name,
            'executive': exec_summary.text,
            'technical': tech_detail.text
        })

    # ë³´ê³ ì„œ ìƒì„±
    report_path = Path(os.path.dirname(__file__)) / "research_reports"
    report_path.mkdir(exist_ok=True)

    # ê²½ì˜ì§„ìš©
    with open(report_path / "executive_summary.md", 'w', encoding='utf-8') as f:
        f.write("# OLED ì—°êµ¬ ì§„í–‰ ë³´ê³  (ê²½ì˜ì§„ìš©)\n\n")
        f.write(f"ì‘ì„±ì¼: {pd.Timestamp.now().strftime('%Y-%m-%d')}\n\n")

        for section in report_sections:
            f.write(f"## {section['experiment']}\n\n")
            f.write(section['executive'])
            f.write("\n\n---\n\n")

    # ì—°êµ¬ì§„ìš©
    with open(report_path / "technical_report.md", 'w', encoding='utf-8') as f:
        f.write("# OLED ì—°êµ¬ ìƒì„¸ ë³´ê³  (ì—°êµ¬ì§„ìš©)\n\n")
        f.write(f"ì‘ì„±ì¼: {pd.Timestamp.now().strftime('%Y-%m-%d')}\n\n")

        for section in report_sections:
            f.write(f"## {section['experiment']}\n\n")
            f.write(section['technical'])
            f.write("\n\n---\n\n")

    print(f"\nâœ“ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ:")
    print(f"  - {report_path / 'executive_summary.md'}")
    print(f"  - {report_path / 'technical_report.md'}")


def workflow_3_explanation_quality_evaluation():
    """
    ì›Œí¬í”Œë¡œìš° 3: í†µê³„ ì„¤ëª…ì˜ í’ˆì§ˆ í‰ê°€
    statlinguaë¡œ ìƒì„±í•œ ì„¤ëª…ì„ vitalsë¡œ í‰ê°€
    """
    print("\n" + "="*70)
    print("ì›Œí¬í”Œë¡œìš° 3: í†µê³„ ì„¤ëª… í’ˆì§ˆ í‰ê°€")
    print("="*70)

    # ì—¬ëŸ¬ í†µê³„ ëª¨ë¸
    np.random.seed(100)

    models_data = {
        'simple_regression': {
            'data': pd.DataFrame({
                'y': np.random.randn(50),
                'x': np.random.randn(50)
            }),
            'description': "ë‹¨ìˆœ ì„ í˜•íšŒê·€"
        },
        'multiple_regression': {
            'data': pd.DataFrame({
                'y': np.random.randn(50),
                'x1': np.random.randn(50),
                'x2': np.random.randn(50),
                'x3': np.random.randn(50)
            }),
            'description': "ë‹¤ì¤‘ ì„ í˜•íšŒê·€"
        }
    }

    client = Anthropic()
    explainer = StatLinguaExplainer(client=client)

    # ì„¤ëª… ìƒì„±
    explanations = {}

    for name, info in models_data.items():
        data = info['data']
        y_col = 'y'
        X_cols = [c for c in data.columns if c != 'y']

        X = sm.add_constant(data[X_cols])
        model = sm.OLS(data[y_col], X)
        results = model.fit()

        # noviceìš© ì„¤ëª… ìƒì„±
        explanation = explainer.explain(
            results,
            audience="novice",
            verbosity="moderate"
        )

        explanations[name] = explanation.text

    # vitalsë¡œ í’ˆì§ˆ í‰ê°€
    eval_dataset = pd.DataFrame({
        'input': [
            f"{info['description']} ê²°ê³¼ë¥¼ ì´ˆë³´ìì—ê²Œ ì„¤ëª…í•˜ì„¸ìš”"
            for info in models_data.values()
        ],
        'target': [
            "ëª…í™•ì„±, ì •í™•ì„±, ì ‘ê·¼ì„±ì„ ëª¨ë‘ ê°–ì¶˜ ì„¤ëª…"
            for _ in models_data
        ]
    })

    def explanation_solver(inputs, **kwargs):
        # ì´ë¯¸ ìƒì„±ëœ ì„¤ëª… ì‚¬ìš©
        return {
            'result': list(explanations.values()),
            'solver_metadata': [{'pre_generated': True}] * len(explanations)
        }

    quality_task = Task(
        dataset=eval_dataset,
        solver=explanation_solver,
        scorer=model_graded_qa(
            client=client,
            instructions="""
í†µê³„ ì„¤ëª…ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
1. í†µê³„ì ìœ¼ë¡œ ì •í™•í•œê°€?
2. ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
3. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ í¬í•¨í•˜ëŠ”ê°€?
4. ì‹¤ë¬´ì  ì˜ë¯¸ë¥¼ ì„¤ëª…í•˜ëŠ”ê°€?
"""
        ),
        name="explanation_quality"
    )

    quality_task.eval(view=True)


if __name__ == "__main__":
    if not os.getenv("ANTHROPIC_API_KEY"):
        print("ê²½ê³ : ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        print("ì‚¬ìš©ë²•: export ANTHROPIC_API_KEY='your-api-key'")
        exit(1)

    # ì‹¤í–‰
    workflow_1_weekly_mentoring_automation()
    workflow_2_research_report_automation()
    workflow_3_explanation_quality_evaluation()

    print("\n" + "="*70)
    print("ëª¨ë“  ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
    print("="*70)
